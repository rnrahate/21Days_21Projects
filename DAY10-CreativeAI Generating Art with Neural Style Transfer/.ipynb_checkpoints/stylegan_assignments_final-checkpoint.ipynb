{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa198f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os, sys, subprocess, platform\n",
    "from pathlib import Path\n",
    "\n",
    "# Hardcoded path where you want the stylegan2 repo to live on your Windows machine\n",
    "hardcoded_repo_path = r\"C:\\Users\\Asus\\Documents\\21_Days_21_Projects_GFG\\stylegan2-ada-pytorch\"\n",
    "\n",
    "# If the hardcoded path exists, use it. Otherwise clone into current working dir (fallback)\n",
    "if os.path.exists(hardcoded_repo_path):\n",
    "    repo_path = hardcoded_repo_path\n",
    "else:\n",
    "    repo_path = os.path.abspath(\"stylegan2-ada-pytorch\")\n",
    "    if not os.path.exists(repo_path):\n",
    "        print(\"Cloning NVlabs/stylegan2-ada-pytorch into\", repo_path)\n",
    "        !git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git \"{repo_path}\"\n",
    "\n",
    "# Ensure repo path is in sys.path so we can import dnnlib and legacy\n",
    "if repo_path not in sys.path:\n",
    "    sys.path.insert(0, repo_path)\n",
    "    print(\"Added to sys.path:\", repo_path)\n",
    "else:\n",
    "    print(\"Repo already in sys.path:\", repo_path)\n",
    "\n",
    "# Quick verification: list some files\n",
    "print(\"Files in repo_path (top-level):\", os.listdir(repo_path)[:20])\n",
    "\n",
    "# Try import (wrapped in try/except to provide friendlier message)\n",
    "try:\n",
    "    import dnnlib, legacy  # noqa: F401\n",
    "    print(\"✅ dnnlib and legacy imported successfully from\", repo_path)\n",
    "except Exception as e:\n",
    "    print(\"❗ Could not import dnnlib/legacy. If running on a remote host, ensure the repo path is correct.\")\n",
    "    print(\"Import error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69bbe97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports and device setup\n",
    "import os, sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from huggingface_hub import hf_hub_download\n",
    "import dnnlib, legacy\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad666461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pretrained StyleGAN2-ADA generator (FFHQ)\n",
    "network_url = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
    "print(\"Loading generator from:\", network_url)\n",
    "\n",
    "with dnnlib.util.open_url(network_url) as f:\n",
    "    G = legacy.load_network_pkl(f)['G_ema'].to(device)  # type: ignore\n",
    "\n",
    "print(\"Loaded generator G (G.synthesis and G.mapping available).\")\n",
    "# Show output shape info\n",
    "print(\"z_dim:\", G.z_dim, \"w_dim (if present):\", getattr(G, \"w_dim\", \"N/A\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d273b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions: mapping/synthesis wrappers, display, save\n",
    "import imageio\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "def generate_image_from_w(G, w, truncation_psi=0.7):\n",
    "    # w expected shape: [1, num_ws, w_dim] (StyleGAN2-ADA mapping output)\n",
    "    img = G.synthesis(w, noise_mode='const')  # returns tensor in range [-1,1]\n",
    "    img = (img.clamp(-1,1) + 1) * 127.5\n",
    "    img = img.permute(0,2,3,1).cpu().numpy().astype(np.uint8)  # [H,W,C]\n",
    "    return img[0]\n",
    "\n",
    "def show_images(imgs, titles=None, cols=5, size=3):\n",
    "    rows = (len(imgs)+cols-1)//cols\n",
    "    plt.figure(figsize=(cols*size, rows*size))\n",
    "    for i,img in enumerate(imgs):\n",
    "        plt.subplot(rows, cols, i+1)\n",
    "        plt.imshow(img)\n",
    "        plt.axis('off')\n",
    "        if titles: plt.title(titles[i])\n",
    "    plt.show()\n",
    "\n",
    "def save_image(img_array, path):\n",
    "    # img_array is uint8 HxWxC\n",
    "    Image.fromarray(img_array).save(path)\n",
    "    print(\"Saved:\", path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f3a00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download precomputed boundaries (gender, age) from Hugging Face (if available)\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "gender_path = None\n",
    "age_path = None\n",
    "try:\n",
    "    print(\"Attempting to download gender and age boundaries from HuggingFace repo 'yuval-alaluf/stylegan2-ffhq' ...\")\n",
    "    gender_path = hf_hub_download(repo_id=\"yuval-alaluf/stylegan2-ffhq\", filename=\"boundaries/gender_boundary.npy\")\n",
    "    age_path = hf_hub_download(repo_id=\"yuval-alaluf/stylegan2-ffhq\", filename=\"boundaries/age_boundary.npy\")\n",
    "    print(\"Downloaded boundaries to:\", gender_path, age_path)\n",
    "except Exception as e:\n",
    "    print(\"Could not download boundaries automatically:\", e)\n",
    "    print(\"Please manually download 'gender_boundary.npy' and 'age_boundary.npy' and place them in this working directory or provide their paths. For example, from the InterFaceGAN / HuggingFace boundary sources.\")\n",
    "\n",
    "# Load if found\n",
    "if gender_path and age_path:\n",
    "    gender_vec = np.load(gender_path)\n",
    "    age_vec = np.load(age_path)\n",
    "    print(\"Loaded gender_vec shape:\", gender_vec.shape, \"age_vec shape:\", age_vec.shape)\n",
    "else:\n",
    "    gender_vec = None\n",
    "    age_vec = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd4aaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1: Gender manipulation (generate 10 variations male -> female)\n",
    "if gender_vec is None:\n",
    "    print(\"gender_vec not available. Please provide 'gender_boundary.npy' or let the previous cell download it for you.\")\n",
    "else:\n",
    "    # sample random z, map to w\n",
    "    z = torch.randn([1, G.z_dim], device=device)\n",
    "    w = G.mapping(z, None)  # [1, num_ws, w_dim]\n",
    "    # prepare delta to broadcast across layers (num_ws)\n",
    "    delta = torch.tensor(gender_vec, dtype=torch.float32, device=device).view(1,1,-1)  # [1,1,w_dim]\n",
    "    delta = delta.repeat(1, w.shape[1], 1)  # [1,num_ws,w_dim]\n",
    "    steps = np.linspace(-3, 3, 10)\n",
    "    imgs = []\n",
    "    titles = []\n",
    "    outdir = Path(\"outputs/gender\")\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, s in enumerate(steps):\n",
    "        w_edit = w + float(s) * delta\n",
    "        img = generate_image_from_w(G, w_edit)\n",
    "        imgs.append(img)\n",
    "        titles.append(f\"s={round(float(s),2)}\")\n",
    "        save_image(img, outdir / f\"gender_variation_{i}.png\")\n",
    "    show_images(imgs, titles=titles, cols=5, size=3)\n",
    "    print(\"Saved gender variations to:\", outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f750b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 2: Age manipulation (generate 10 variations younger -> older)\n",
    "if age_vec is None:\n",
    "    print(\"age_vec not available. Please provide 'age_boundary.npy' or let the previous cell download it for you.\")\n",
    "else:\n",
    "    z = torch.randn([1, G.z_dim], device=device)\n",
    "    w = G.mapping(z, None)\n",
    "    delta_age = torch.tensor(age_vec, dtype=torch.float32, device=device).view(1,1,-1).repeat(1, w.shape[1], 1)\n",
    "    steps = np.linspace(-3, 3, 10)\n",
    "    imgs = []\n",
    "    titles = []\n",
    "    outdir = Path(\"outputs/age\")\n",
    "    outdir.mkdir(parents=True, exist_ok=True)\n",
    "    for i, s in enumerate(steps):\n",
    "        w_edit = w + float(s) * delta_age\n",
    "        img = generate_image_from_w(G, w_edit)\n",
    "        imgs.append(img)\n",
    "        titles.append(f\"s={round(float(s),2)}\")\n",
    "        save_image(img, outdir / f\"age_variation_{i}.png\")\n",
    "    show_images(imgs, titles=titles, cols=5, size=3)\n",
    "    print(\"Saved age variations to:\", outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57aa29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3: Style mixing between two random samples\n",
    "# Sample two z vectors\n",
    "z1 = torch.randn([1, G.z_dim], device=device)\n",
    "z2 = torch.randn([1, G.z_dim], device=device)\n",
    "w1 = G.mapping(z1, None)  # [1,num_ws,w_dim]\n",
    "w2 = G.mapping(z2, None)\n",
    "\n",
    "# Simple style-mixing: take first N layers from w1 and rest from w2\n",
    "N = w1.shape[1] // 2  # e.g., half-half\n",
    "w_mixed = w1.clone()\n",
    "w_mixed[:, :N, :] = w2[:, :N, :]\n",
    "\n",
    "img1 = generate_image_from_w(G, w1)\n",
    "img2 = generate_image_from_w(G, w2)\n",
    "img_mix = generate_image_from_w(G, w_mixed)\n",
    "\n",
    "outdir = Path(\"outputs/stylemix\")\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "save_image(img1, outdir / \"style_1.png\")\n",
    "save_image(img2, outdir / \"style_2.png\")\n",
    "save_image(img_mix, outdir / \"style_mixed.png\")\n",
    "\n",
    "show_images([img1, img2, img_mix], titles=[\"A\", \"B\", \"Mixed\"], cols=3, size=4)\n",
    "print(\"Saved style-mixing outputs to:\", outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170fa9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes and Troubleshooting\n",
    "# - If the notebook fails to import dnnlib/legacy, ensure the repo is cloned at the hardcoded path or in the notebook folder.\n",
    "# - If Hugging Face download fails, manually download 'gender_boundary.npy' and 'age_boundary.npy' from 'yuval-alaluf/stylegan2-ffhq' or InterFaceGAN resources and place them in the working directory.\n",
    "# - On Windows, if cloning into the hardcoded path requires admin privileges, run Jupyter as administrator or change the path to somewhere you have write access.\n",
    "# - If CUDA is not available, the notebook will run on CPU (much slower). Consider using a GPU runtime.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
